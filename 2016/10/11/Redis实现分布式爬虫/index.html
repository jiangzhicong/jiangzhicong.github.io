<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>基于Redis的分布式爬虫系统 | Welcome to miracle-online</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="RedisRedis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。
和Redis类">
<meta property="og:type" content="article">
<meta property="og:title" content="基于Redis的分布式爬虫系统">
<meta property="og:url" content="http://yoursite.com/2016/10/11/Redis实现分布式爬虫/index.html">
<meta property="og:site_name" content="Welcome to miracle-online">
<meta property="og:description" content="RedisRedis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。
和Redis类">
<meta property="og:image" content="http://oergbco0f.bkt.clouddn.com/Scrapy%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F.png">
<meta property="og:image" content="http://oergbco0f.bkt.clouddn.com/%E5%9F%BA%E4%BA%8ERedis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%ABWeb%20API%E7%B3%BB%E7%BB%9F%E6%B5%81%E7%A8%8B%E5%9B%BE.png">
<meta property="og:updated_time" content="2016-10-11T09:07:06.467Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="基于Redis的分布式爬虫系统">
<meta name="twitter:description" content="RedisRedis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。
和Redis类">
<meta name="twitter:image" content="http://oergbco0f.bkt.clouddn.com/Scrapy%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F.png">
  
    <link rel="alternate" href="/atom.xml" title="Welcome to miracle-online" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Welcome to miracle-online</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Redis实现分布式爬虫" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/10/11/Redis实现分布式爬虫/" class="article-date">
  <time datetime="2016-10-11T09:07:06.475Z" itemprop="datePublished">2016-10-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      基于Redis的分布式爬虫系统
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。</p>
<p>和Redis类似的有<code>Memcached</code>，同样是基于内存的高性能缓存数据库，Redis是单线程模型，而Memcached支持多线程；但Memcached仅仅支持Key-Value存储，而Redis支持多种数据结构，这也是文中选用Redis的原因之一。<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzYwNjQ3NA==&amp;mid=2651296789&amp;idx=1&amp;sn=7e31c22b64dcf0a200e00b3868001621&amp;scene=1&amp;srcid=0710WgctFwtahN3cTjvmaJYr#wechat_redirect" target="_blank" rel="external">了解更多区别</a></p>
<p>虽然Redis是单线程模型，但其性能远远满足我们业务的需求，单机Redis读写可以达到10万次每秒。有大牛尝试将Redis改为多线程模型，最后可以达到每秒读写30万次+。利用Redis的list数据结构，可以实现发布-订阅模型，或类似消息队列功能，但不同于<code>MQ</code>，<code>Kafka</code>等消息队列，Redis是高实时性高性能的消息队列。</p>
<h3 id="Scrapy实现分布式"><a href="#Scrapy实现分布式" class="headerlink" title="Scrapy实现分布式"></a>Scrapy实现分布式</h3><h5 id="scrapy-redis"><a href="#scrapy-redis" class="headerlink" title="scrapy-redis"></a>scrapy-redis</h5><p>Github有一个叫<a href="https://github.com/rolando/scrapy-redis" target="_blank" rel="external">scrapy-redis</a>的项目，通过Redis实现了分布式爬虫。Scrapy原生的任务调度是基于文件系统，通过JOBDIR指定任务信息存储的路径。这样只能在单机执行crawl。scrapy-redis修改了<code>Scheduler</code>，<code>Item Pipeline</code>等组件，将任务和数据信息的存取放到redis queue里，使多台服务器可以同时执行crawl和tems process，大大提高了数据爬取和处理的效率。</p>
<h5 id="使用redis队列"><a href="#使用redis队列" class="headerlink" title="使用redis队列"></a>使用redis队列</h5><p>实现Scrapy爬虫分布式，这里还有个简单粗暴的办法，就是在<code>start_requests()</code>方法中，写一个死循环，循环中监听一个Redis队列，一旦发现有消息就将其<code>pop()</code>，然后将请求放入到Scrapy原生的请求队列中，Scrapy的其他线程会从队列取出请求并继续执行。这巧妙的利用了Redis的高性能以及Scrapy的多线程模型。</p>
<p><img src="http://oergbco0f.bkt.clouddn.com/Scrapy%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F.png" alt="Scrapy中加入Redis队列"></p>
<h6 id="scrapy多线程模型"><a href="#scrapy多线程模型" class="headerlink" title="scrapy多线程模型"></a><em>scrapy多线程模型</em></h6><p>Scrapy的<code>settings</code>中可以设置多线程的数目，其多线程大概是这样工作的，主线程不停的通过<code>yield</code>将请求push到scrapy请求队列，子线程会并发的从请求队列中pop请求，然后将请求交由<code>Downloader</code>处理，会有专门的线程来同时处理返回的Response。</p>
<h5 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h5><p>使用redis队列的好处就是实现简单，不用修改Scrapy源码。但其缺点缺也是显而易见的，其请求队列冗余了，且Scrapy需要一直运行。Python常驻内存的应用，会存在<strong>内存回收</strong>的问题，由于自动回收机制并不能很好的回收垃圾，导致进程占用内存越来越多，直至爆满。亲测在Python下，手动回收垃圾，也不能够彻底解决这个问题，这种问题在PHP等语言中也是存在的。</p>
<p>解决办法有两个，<strong>定期重启进程和使用多进程</strong>。线程生成的一个对象并不会随线程结束而销毁，而进程生成的对象会随进程结束而释放。所以将所有生成对象的操作都放到新进程中执行，一个新进程的生命周期即为一个爬虫请求的生命周期。</p>
<h5 id="简单爬虫实现分布式"><a href="#简单爬虫实现分布式" class="headerlink" title="简单爬虫实现分布式"></a>简单爬虫实现分布式</h5><p>Scrapy是一个很强大的爬虫框架，但很多时候，我们编写的爬虫比较简单，所以根本用不着Scrapy，使用Pyhton第三方库<code>requests</code>能很快的编写一个简单爬虫。但很多时候，我们需要将这些简单爬虫部署到多台机器上，如上使用Redis方法，也能很好的实现简单爬虫分布式。</p>
<h3 id="基于Redis实现分布式爬虫Web-API系统"><a href="#基于Redis实现分布式爬虫Web-API系统" class="headerlink" title="基于Redis实现分布式爬虫Web API系统"></a>基于Redis实现分布式爬虫Web API系统</h3><h5 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h5><p>很多时候，我们需要将爬虫实时抓取的数据通过Web API响应给用户。比如Web API提供一个百度百科查询功能，用户请求Web API，传入一个关键词，系统实时查询抓取百度百科内容，然后返回给用户。</p>
<h5 id="Web-API"><a href="#Web-API" class="headerlink" title="Web API"></a>Web API</h5><p>每个开发语言都有实现Web API的多种方式，对于Python，可以使用Flask框架，能够快速搭建web应用。Flask是一个使用Python编写的轻量级Web应用框架，基于<code>Werkzeug WSGI</code>工具箱和<code>Jinja2</code>模板引擎。</p>
<h5 id="Scrapy爬虫"><a href="#Scrapy爬虫" class="headerlink" title="Scrapy爬虫"></a>Scrapy爬虫</h5><p>针对Scrapy爬虫，简单的处理流程是，当flask收到一个用户的请求时，然后通过子进程（<code>subprocess</code>）调用scrapy爬取数据，然后通过管道将数据返回。这样做有个很大的缺陷，即scrapy在初始化的时候，需要花费数秒的时间，对于高实时性的Web API来说，是不可容忍的。</p>
<p>针对这种情况，有三种解决办法。第一种是使用Scrapy自带的web service， 服务通过<code>JSON-RPC 2.0</code>协议提供大部分的资源，web服务资源的实现采用了Twisted Web API。第二种是修改Scrapy源码，将Flask和scrapy整合到一起。第三种是前文中的办法，直接在<code>start_requests()</code>方法中监听Redis。</p>
<p>对于第一种方法，不太适合做对外提供服务的Web API，第二种方法工程较大，而第三种方法是一个折中的方案，也是我们目前采用的方案。通过让Scrapy一直处于运行状态，就减少了Scrapy初始化的时间，达到了Web API高实时性的需求。</p>
<h5 id="需要分布式爬虫？"><a href="#需要分布式爬虫？" class="headerlink" title="需要分布式爬虫？"></a>需要分布式爬虫？</h5><p>分布式爬虫拥有如下优点：</p>
<ul>
<li><strong>高并发</strong>，单机服务器资源有限，使用分布式爬虫可以获得更高的并发量。</li>
<li><strong>高可用性</strong>，爬虫部署到N台服务器，即使N-1台服务器故障，也不会影响到服务。</li>
<li><strong>可伸缩性</strong>，添加爬虫或减少爬虫，不会对服务造成任何影响。</li>
<li><strong>经济性</strong>，部分爬虫可以部署到廉价机器上，甚至自己电脑上。</li>
</ul>
<h5 id="使用Redis"><a href="#使用Redis" class="headerlink" title="使用Redis"></a>使用Redis</h5><p>flask接收到一个请求，然后将请求push到Redis队列，每个爬虫实现一个<code>listener</code>方法，监听这个Redis队列，即编写一个死循环，循环里面使用<code>brpop()</code>方法获取队列消息。</p>
<p><code>brpop</code>不同于<code>pop</code>方法，其采用阻塞式，如果没有获取到消息，会一直阻塞，直到取到消息，当然也可以超时时间，我一般设置为5s。这样做的好处是减少Redis的访问次数，避免循环对Redis造成大量访问，影响Redis性能。</p>
<p>取到Redis消息后，使用<strong>多进程</strong>调用爬虫执行，使用多进程而不使用多线程理由如下：</p>
<ul>
<li>多线程不能利用多核CPU，不能实现真正意义上并发。</li>
<li>新进程执行结束后，新进程内生成的对象会随进程结束而销毁，实现了内存的回收，对于常驻内存的应用，这点至关重要。</li>
</ul>
<p>接收到一个请求，就开启一个新进程，这样可能会导致进程数目过多，所以我们需要对进程数目进行限制。每创建一个新进程，就将其add到一个全局list，每次从Redis队列取消息之前，通过<code>poll()</code>方法判断目前存活的进程，如果存活的进程大于阈值，则睡眠一小段时间，然后进行下一次循环。这个阈值一般设置为CPU核心数，当然如果是IO密集型应用，可以将阈值设置的更高一点。</p>
<p>爬虫抓取到数据后，需要将数据传给flask，flask再响应给用户。数据传输的方式有很多种，如果是极少量的数据，可以直接通过Redis将数据写回，flask只需要阻塞地读就可以了。如果数据量较多，可以使用<code>MongoDB</code>，<code>Mysql</code>等数据库，毕竟数据库一般查询消耗的时间在数十毫秒内，完全满足性能需求。另外将爬虫数据存入持久化数据库，比如Mysql，还可以实现记录日志功能，方便以后审计。</p>
<p>所以整个流程就是，flask接收到用户请求，将请求push到Redis队列，分布式爬虫从Redis队列<code>brpop</code>消息，然后开启多进程爬取数据，最后通过Mysql将数据写回，flask从Mysql取回爬虫数据，然后响应给用户。</p>
<p><img src="http://oergbco0f.bkt.clouddn.com/%E5%9F%BA%E4%BA%8ERedis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%ABWeb%20API%E7%B3%BB%E7%BB%9F%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="基于Redis实现分布式爬虫Web API系统流程图"></p>
<h5 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h5><p>以下是本套系统设计方案的优势：</p>
<ul>
<li><strong>解耦合</strong>，通过Redis降低Web API和爬虫耦合程度，不管Web API和爬虫使用什么开发语言编写，使用什么平台部署，都不会有任何影响。</li>
<li><strong>分布式</strong>，拥有分布式爬虫的高并发，高可用，可伸缩，经济性等优点。</li>
<li><strong>负载均衡</strong>，由于多个爬虫监听同一个Redis队列，所以会出现抢消息机制，谁抢到消息谁执行爬虫，各个爬虫抢到消息的机会均等。当然还可以设置抢消息的时间间隔来使负载更均衡，比如在抢到一条消息之后，需要等待一定时间才能去抢下一条消息。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/10/11/Redis实现分布式爬虫/" data-id="ciu59nq5h000197669hn72ysv" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/10/10/Python并发/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Python并发</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/10/11/Redis实现分布式爬虫/">基于Redis的分布式爬虫系统</a>
          </li>
        
          <li>
            <a href="/2016/10/10/Python并发/">Python并发</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Jiang Zhicong<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>